{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d4e661",
   "metadata": {},
   "source": [
    "## ðŸš€ Intel GPU Setup Instructions\n",
    "\n",
    "This notebook is configured to use **Intel Iris Xe Graphics** for GPU acceleration via DirectML.\n",
    "\n",
    "### âœ… DirectML Installation (For Intel/AMD GPUs on Windows)\n",
    "\n",
    "DirectML has been installed in your environment. The notebook will automatically detect and use your Intel Iris Xe Graphics.\n",
    "\n",
    "If you need to reinstall:\n",
    "```bash\n",
    "pip install torch-directml==0.2.5.dev240914\n",
    "```\n",
    "\n",
    "### ðŸ“‹ System Requirements\n",
    "- Windows 10/11\n",
    "- Intel Iris Xe Graphics or AMD GPU\n",
    "- PyTorch 2.0+\n",
    "- DirectML backend\n",
    "\n",
    "### ðŸŽ® What to Expect\n",
    "- **GPU Acceleration**: Your Intel Iris Xe Graphics will be used for training\n",
    "- **Performance**: Faster than CPU, though not as fast as NVIDIA CUDA\n",
    "- **Compatibility**: Works with integrated Intel GPUs on Windows\n",
    "\n",
    "**Note:** After running cell 2, you should see \"DirectML (Intel/AMD) available: True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17baa1d",
   "metadata": {},
   "source": [
    "# Unified Medical X-ray Disease Detection Model\n",
    "## Training a Single Model to Detect All Diseases\n",
    "\n",
    "This notebook trains a unified deep learning model that can detect:\n",
    "- **Chest conditions**: COVID-19, Pneumonia, Tuberculosis, Normal Chest\n",
    "- **Bone conditions**: Osteoporosis, Normal Bone\n",
    "- **Fractures**: Fractured, Non-Fractured\n",
    "\n",
    "### Models to train:\n",
    "1. ResNet50\n",
    "2. DenseNet121\n",
    "3. EfficientNetB0\n",
    "\n",
    "All models will be trained on the unified dataset with 8 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check for DirectML (Intel/AMD GPU support on Windows)\n",
    "has_dml = False\n",
    "try:\n",
    "    import torch_directml\n",
    "    has_dml = True\n",
    "    dml_device = torch_directml.device()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Check for other GPU backends\n",
    "has_xpu = hasattr(torch, 'xpu') and torch.xpu.is_available()\n",
    "has_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(f\"\\nðŸŽ® GPU Detection:\")\n",
    "print(f\"  CUDA (NVIDIA) available: {has_cuda}\")\n",
    "print(f\"  XPU (Intel Extension) available: {has_xpu}\")\n",
    "print(f\"  DirectML (Intel/AMD) available: {has_dml}\")\n",
    "\n",
    "if has_dml:\n",
    "    print(f\"\\nâœ“ DirectML backend detected (Intel/AMD GPU)\")\n",
    "    print(f\"  This will enable GPU acceleration on your Intel Iris Xe Graphics\")\n",
    "elif has_xpu:\n",
    "    print(f\"\\nâœ“ Intel GPU detected via XPU backend\")\n",
    "    print(f\"  Device: {torch.xpu.get_device_name(0)}\")\n",
    "    print(f\"  Number of XPU devices: {torch.xpu.device_count()}\")\n",
    "elif has_cuda:\n",
    "    print(f\"\\nâœ“ NVIDIA CUDA GPU detected\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ No GPU acceleration detected. Will use CPU.\")\n",
    "    print(f\"\\nðŸ’¡ To enable Intel Iris Xe GPU acceleration:\")\n",
    "    print(f\"  pip install torch-directml==0.2.5.dev240914\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c023db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_DIR = Path('unified_dataset')\n",
    "MODEL_SAVE_DIR = Path('models')\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Unified class labels (8 classes)\n",
    "CLASSES = [\n",
    "    'COVID19',\n",
    "    'PNEUMONIA',\n",
    "    'TUBERCULOSIS',\n",
    "    'NORMAL_CHEST',\n",
    "    'OSTEOPOROSIS',\n",
    "    'NORMAL_BONE',\n",
    "    'FRACTURED',\n",
    "    'NON_FRACTURED'\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Device selection - prioritize DirectML > Intel XPU > CUDA > CPU\n",
    "if has_dml:\n",
    "    DEVICE = dml_device  # DirectML device for Intel/AMD GPU\n",
    "    DEVICE_TYPE = 'directml'\n",
    "    print(f\"âœ“ Using DirectML device (Intel Iris Xe Graphics)\")\n",
    "elif has_xpu:\n",
    "    DEVICE = torch.device('xpu:0')  # Intel GPU via XPU\n",
    "    DEVICE_TYPE = 'xpu'\n",
    "    print(f\"âœ“ Using Intel GPU (XPU): {torch.xpu.get_device_name(0)}\")\n",
    "elif has_cuda:\n",
    "    DEVICE = torch.device('cuda:0')  # NVIDIA GPU\n",
    "    DEVICE_TYPE = 'cuda'\n",
    "    print(f\"âœ“ Using NVIDIA GPU (CUDA): {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')  # Fallback to CPU\n",
    "    DEVICE_TYPE = 'cpu'\n",
    "    print(f\"âš ï¸ Using CPU (no GPU acceleration)\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Device type: {DEVICE_TYPE}\")\n",
    "print(f\"  Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"  Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"\\nClasses: {CLASSES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a04c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "info_file = DATASET_DIR / 'dataset_info.json'\n",
    "if info_file.exists():\n",
    "    with open(info_file, 'r') as f:\n",
    "        dataset_info = json.load(f)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Dataset Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        print(f\"\\n{split.upper()} Set:\")\n",
    "        for cls, count in dataset_info['splits'][split].items():\n",
    "            if cls != 'total':\n",
    "                print(f\"  {cls:20s}: {count:6d} images\")\n",
    "        print(f\"  {'TOTAL':20s}: {dataset_info['splits'][split]['total']:6d} images\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"âš ï¸ Dataset info not found. Please run prepare_unified_dataset.py first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class UnifiedXRayDataset(Dataset):\n",
    "    \"\"\"Unified X-ray dataset for all disease types.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to dataset directory (train/val/test)\n",
    "            transform: Optional transform to be applied on images\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.classes = CLASSES\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Load all image paths and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.data_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                class_idx = self.class_to_idx[class_name]\n",
    "                for img_path in class_dir.glob('*.*'):\n",
    "                    if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                        self.images.append(img_path)\n",
    "                        self.labels.append(class_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = UnifiedXRayDataset(DATASET_DIR / 'train', transform=train_transform)\n",
    "val_dataset = UnifiedXRayDataset(DATASET_DIR / 'val', transform=val_test_transform)\n",
    "test_dataset = UnifiedXRayDataset(DATASET_DIR / 'test', transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "# Note: pin_memory only works with CUDA, disable for DirectML and other backends\n",
    "use_pin_memory = (DEVICE_TYPE == 'cuda')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=0,  # Set to 0 for notebook compatibility\n",
    "    pin_memory=use_pin_memory\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    pin_memory=use_pin_memory\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    pin_memory=use_pin_memory\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Dataset Sizes:\")\n",
    "print(f\"  Training: {len(train_dataset)} images\")\n",
    "print(f\"  Validation: {len(val_dataset)} images\")\n",
    "print(f\"  Test: {len(test_dataset)} images\")\n",
    "print(f\"\\n  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Pin memory: {use_pin_memory}\")\n",
    "print(f\"\\nðŸ’¡ Note: DirectML GPU acceleration is enabled for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108385fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def show_sample_images(dataset, num_samples=8):\n",
    "    \"\"\"Display sample images from dataset.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    for idx, ax in zip(indices, axes):\n",
    "        img, label = dataset[idx]\n",
    "        \n",
    "        # Denormalize image for display\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{CLASSES[label]}\", fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample Training Images:\")\n",
    "show_sample_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfeffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Classes\n",
    "\n",
    "class UnifiedResNet50(nn.Module):\n",
    "    \"\"\"ResNet50 for unified disease classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super(UnifiedResNet50, self).__init__()\n",
    "        self.backbone = models.resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.backbone.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "class UnifiedDenseNet121(nn.Module):\n",
    "    \"\"\"DenseNet121 for unified disease classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super(UnifiedDenseNet121, self).__init__()\n",
    "        self.backbone = models.densenet121(weights='DEFAULT' if pretrained else None)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.backbone.classifier.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "class UnifiedEfficientNetB0(nn.Module):\n",
    "    \"\"\"EfficientNetB0 for unified disease classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super(UnifiedEfficientNetB0, self).__init__()\n",
    "        self.backbone = models.efficientnet_b0(weights='DEFAULT' if pretrained else None)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.backbone.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "print(\"âœ“ Model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Functions\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'acc': 100. * correct / total})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'acc': 100. * correct / total})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, model_name, train_loader, val_loader, num_epochs=NUM_EPOCHS):\n",
    "    \"\"\"Complete training loop with DirectML support.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"Device: {DEVICE} ({DEVICE_TYPE})\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            save_path = MODEL_SAVE_DIR / f'unified_{model_name}.pth'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"âœ“ Saved best model to {save_path} (Val Acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        # Clear cache for GPU memory management\n",
    "        # Note: DirectML doesn't have explicit cache clearing, but we can use garbage collection\n",
    "        if epoch % 5 == 0 and DEVICE_TYPE == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training Complete! Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"âœ“ Training functions defined\")\n",
    "print(f\"âœ“ Using device: {DEVICE_TYPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4e54b",
   "metadata": {},
   "source": [
    "## Train ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "resnet_model = UnifiedResNet50(num_classes=NUM_CLASSES, pretrained=True)\n",
    "resnet_model, resnet_history = train_model(resnet_model, 'ResNet50', train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861060e7",
   "metadata": {},
   "source": [
    "## Train DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DenseNet121\n",
    "densenet_model = UnifiedDenseNet121(num_classes=NUM_CLASSES, pretrained=True)\n",
    "densenet_model, densenet_history = train_model(densenet_model, 'DenseNet121', train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28c71f",
   "metadata": {},
   "source": [
    "## Train EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB0\n",
    "efficientnet_model = UnifiedEfficientNetB0(num_classes=NUM_CLASSES, pretrained=True)\n",
    "efficientnet_model, efficientnet_history = train_model(efficientnet_model, 'EfficientNetB0', train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(histories, model_names):\n",
    "    \"\"\"Plot training and validation metrics.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    for history, name in zip(histories, model_names):\n",
    "        axes[0].plot(history['train_loss'], label=f'{name} Train', linestyle='--')\n",
    "        axes[0].plot(history['val_loss'], label=f'{name} Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    for history, name in zip(histories, model_names):\n",
    "        axes[1].plot(history['train_acc'], label=f'{name} Train', linestyle='--')\n",
    "        axes[1].plot(history['val_acc'], label=f'{name} Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(\n",
    "    [resnet_history, densenet_history, efficientnet_history],\n",
    "    ['ResNet50', 'DenseNet121', 'EfficientNetB0']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on Test Set\n",
    "def evaluate_model(model, model_name, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Evaluating {model_name} on Test Set\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=CLASSES, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "resnet_acc, _, _ = evaluate_model(resnet_model, 'ResNet50', test_loader, DEVICE)\n",
    "densenet_acc, _, _ = evaluate_model(densenet_model, 'DenseNet121', test_loader, DEVICE)\n",
    "efficientnet_acc, _, _ = evaluate_model(efficientnet_model, 'EfficientNetB0', test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c59e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTest Set Accuracies:\")\n",
    "print(f\"  ResNet50:        {resnet_acc * 100:.2f}%\")\n",
    "print(f\"  DenseNet121:     {densenet_acc * 100:.2f}%\")\n",
    "print(f\"  EfficientNetB0:  {efficientnet_acc * 100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'classes': CLASSES,\n",
    "    'models': {\n",
    "        'ResNet50': {\n",
    "            'path': 'models/unified_ResNet50.pth',\n",
    "            'test_accuracy': float(resnet_acc)\n",
    "        },\n",
    "        'DenseNet121': {\n",
    "            'path': 'models/unified_DenseNet121.pth',\n",
    "            'test_accuracy': float(densenet_acc)\n",
    "        },\n",
    "        'EfficientNetB0': {\n",
    "            'path': 'models/unified_EfficientNetB0.pth',\n",
    "            'test_accuracy': float(efficientnet_acc)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('unified_model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ“ Model information saved to 'unified_model_info.json'\")\n",
    "print(\"\\nâœ… Training Complete! You can now use these models in your application.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
